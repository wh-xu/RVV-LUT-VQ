#!/usr/bin/env python3
"""
è‡ªåŠ¨åŒ–å®éªŒè¿è¡Œè„šæœ¬
å®Œæ•´çš„PQ vs RQæ€§èƒ½å¯¹æ¯”å®éªŒ
"""

import os
import sys
import logging
import time
import math
import csv
import subprocess
import json
from typing import Dict, List, Tuple, Any
from dataclasses import dataclass

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('experiment.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class ExperimentConfig:
    """å®éªŒé…ç½®ç±»"""
    dataset: str
    algorithm: str
    k: int
    m: int
    target_bits: int
    actual_bits: int
    ideal_m: float
    dimension: int

class ExperimentRunner:
    """è‡ªåŠ¨åŒ–å®éªŒè¿è¡Œå™¨"""
    
    def __init__(self):
        self.datasets = ["glove", "sift1m", "gist1m", "deep10m"]
        self.k_values = [4, 8, 16, 32, 64, 128, 256]
        self.target_bits = [32, 64, 128]
        
        # æ•°æ®é›†ç»´åº¦æ˜ å°„
        self.dataset_dimensions = {
            "glove": 100,
            "sift1m": 128, 
            "gist1m": 960,
            "deep10m": 96
        }
        
        # ç®—æ³•ç­–ç•¥æ˜ å°„
        self.algorithm_strategy = {
            "glove": "pq",      # éœ€è¦ç»´åº¦æ•´é™¤
            "sift1m": "pq",     # éœ€è¦ç»´åº¦æ•´é™¤
            "gist1m": "rq",     # ç»´åº¦çµæ´»
            "deep10m": "rq"     # ç»´åº¦çµæ´»
        }
        
        self.results = {
            "build_results": [],
            "search_results": [],
            "errors": []
        }
    
    def get_valid_m_values(self, dataset: str, dimension: int) -> List[int]:
        """è·å–æœ‰æ•ˆçš„Må€¼åˆ—è¡¨"""
        if dataset in ["glove", "sift1m"]:
            # PQç®—æ³•éœ€è¦ç»´åº¦èƒ½è¢«Mæ•´é™¤
            return [m for m in range(1, dimension + 1) if dimension % m == 0]
        else:
            # RQç®—æ³•Må€¼å¯ä»¥ä»»æ„é€‰æ‹©
            return list(range(1, dimension + 1))
    
    def calculate_optimal_m(self, k: int, target_bits: int, dataset: str, dimension: int, algorithm: str) -> Tuple[int, float, int]:
        """è®¡ç®—æœ€ä¼˜Må€¼"""
        # æ ¹æ®ç®—æ³•è°ƒæ•´ideal_mè®¡ç®—
        if algorithm == "4bitfastscan":
            # 4BitFastScanå›ºå®š4-bit
            ideal_m = target_bits / 4
        else:
            # å…¶ä»–ç®—æ³•ä½¿ç”¨log2(K)
            ideal_m = target_bits / math.log2(k)
            
        valid_m_values = self.get_valid_m_values(dataset, dimension)
        
        if dataset in ["glove", "sift1m"]:
            # PQç®—æ³•ï¼šé€‰æ‹©æœ€æ¥è¿‘çš„æœ‰æ•ˆå› å­
            chosen_m = min(valid_m_values, key=lambda m: abs(m - ideal_m))
        else:
            # RQç®—æ³•ï¼šå››èˆäº”å…¥åˆ°æœ€è¿‘æ•´æ•°
            chosen_m = round(ideal_m)
            chosen_m = max(1, min(chosen_m, dimension))  # ç¡®ä¿åœ¨åˆç†èŒƒå›´å†…
        
        # æ ¹æ®ç®—æ³•è®¡ç®—å®é™…bitæ•°
        if algorithm == "4bitfastscan":
            # 4BitFastScanå›ºå®šä½¿ç”¨4-bit
            actual_bits = chosen_m * 4
        else:
            # å…¶ä»–ç®—æ³•ä½¿ç”¨log2(K)
            actual_bits = chosen_m * math.log2(k)
        
        return chosen_m, ideal_m, int(actual_bits)
    
    def select_algorithm(self, dataset: str, k: int) -> str:
        """é€‰æ‹©ç®—æ³•"""
        base_algorithm = self.algorithm_strategy[dataset]
        
        # K=16æ—¶ä¼˜å…ˆä½¿ç”¨FastScan
        if k == 16:
            if base_algorithm == "pq":
                return "4bitfastscan"
            elif base_algorithm == "rq":
                return "rq_fastscan"
        
        return base_algorithm
    
    def generate_experiment_configs(self, dataset: str) -> List[ExperimentConfig]:
        """ç”Ÿæˆå®éªŒé…ç½®"""
        configs = []
        dimension = self.dataset_dimensions[dataset]
        
        logger.info(f"ğŸ“‹ ç”Ÿæˆ{dataset}æ•°æ®é›†å®éªŒé…ç½® (ç»´åº¦={dimension})")
        
        for target_bits in self.target_bits:
            for k in self.k_values:
                algorithm = self.select_algorithm(dataset, k)
                chosen_m, ideal_m, actual_bits = self.calculate_optimal_m(k, target_bits, dataset, dimension, algorithm)
                
                config = ExperimentConfig(
                    dataset=dataset,
                    algorithm=algorithm,
                    k=k,
                    m=chosen_m,
                    target_bits=target_bits,
                    actual_bits=actual_bits,
                    ideal_m=ideal_m,
                    dimension=dimension
                )
                
                configs.append(config)
                logger.info(f"  K={k}, target={target_bits}bits, ideal_M={ideal_m:.2f}, chosen_M={chosen_m}, actual={actual_bits}bits, alg={algorithm}")
        
        logger.info(f"âœ… ç”Ÿæˆ{len(configs)}ä¸ªå®éªŒé…ç½®")
        return configs
    
    def build_single_model(self, config: ExperimentConfig) -> Dict[str, Any]:
        """æ„å»ºå•ä¸ªæ¨¡å‹"""
        logger.info(f"ğŸ”¨ æ„å»ºæ¨¡å‹: {config.dataset}_{config.algorithm}_k{config.k}_m{config.m}")
        
        cmd = [
            "python", "main.py",
            "--mode", "build",
            "--dataset", config.dataset,
            "--algorithm", config.algorithm,
            "--k_values", str(config.k),
            "--m_values", str(config.m)
        ]
        
        start_time = time.time()
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=3600)  # 1å°æ—¶è¶…æ—¶
            
            if result.returncode != 0:
                error_msg = f"æ¨¡å‹æ„å»ºå¤±è´¥: {config.dataset}_{config.algorithm}_k{config.k}_m{config.m}"
                logger.error(f"âŒ {error_msg}")
                logger.error(f"é”™è¯¯è¾“å‡º: {result.stderr}")
                raise RuntimeError(error_msg)
            
            build_time = time.time() - start_time
            
            # ç”Ÿæˆæ¨¡å‹åç§°
            # æ ¹æ®æ•°æ®é›†ç¡®å®šæ­£ç¡®çš„è·ç¦»åº¦é‡
            distance_metrics = {
                "glove": "ip",
                "sift1m": "l2", 
                "gist1m": "l2",
                "deep10m": "ip"
            }
            dist_metric = distance_metrics.get(config.dataset, "l2")
            model_name = f"{config.dataset}_{config.algorithm}_k{config.k}_m{config.m}_{dist_metric}"
            
            result_data = {
                "dataset": config.dataset,
                "algorithm": config.algorithm,
                "k": config.k,
                "m": config.m,
                "target_bits": config.target_bits,
                "actual_bits": config.actual_bits,
                "ideal_m": config.ideal_m,
                "chosen_m": config.m,
                "dimension": config.dimension,
                "status": "Success",
                "build_time": build_time,
                "model_name": model_name
            }
            
            logger.info(f"âœ… æ„å»ºæˆåŠŸ: {model_name} (è€—æ—¶: {build_time:.1f}s)")
            return result_data
            
        except subprocess.TimeoutExpired:
            error_msg = f"æ¨¡å‹æ„å»ºè¶…æ—¶: {config.dataset}_{config.algorithm}_k{config.k}_m{config.m}"
            logger.error(f"âŒ {error_msg}")
            raise RuntimeError(error_msg)
        except Exception as e:
            error_msg = f"æ¨¡å‹æ„å»ºå¼‚å¸¸: {str(e)}"
            logger.error(f"âŒ {error_msg}")
            raise
    
    def run_search_test(self, dataset: str) -> List[Dict[str, Any]]:
        """è¿è¡Œæœç´¢æµ‹è¯•"""
        logger.info(f"ğŸ” æ‰§è¡Œæœç´¢æµ‹è¯•: {dataset}")
        
        cmd = [
            "python", "main.py", 
            "--mode", "search",
            "--dataset", dataset,
            "--recall_k", "1,5,10,100",
            
        ]
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=1800)  # 30åˆ†é’Ÿè¶…æ—¶
            
            if result.returncode != 0:
                error_msg = f"æœç´¢æµ‹è¯•å¤±è´¥: {dataset}"
                logger.error(f"âŒ {error_msg}")
                logger.error(f"é”™è¯¯è¾“å‡º: {result.stderr}")
                raise RuntimeError(error_msg)
            
            logger.info(f"âœ… æœç´¢æµ‹è¯•å®Œæˆ: {dataset}")
            
            # è§£ææœç´¢ç»“æœ
            # è¿™é‡Œéœ€è¦ä»main.pyçš„è¾“å‡ºä¸­è§£æç»“æœï¼Œæˆ–è€…ä¿®æ”¹main.pyè¾“å‡ºJSONæ ¼å¼
            search_results = self.parse_search_output(result.stdout, dataset)
            return search_results
            
        except subprocess.TimeoutExpired:
            error_msg = f"æœç´¢æµ‹è¯•è¶…æ—¶: {dataset}"
            logger.error(f"âŒ {error_msg}")
            raise RuntimeError(error_msg)
        except Exception as e:
            error_msg = f"æœç´¢æµ‹è¯•å¼‚å¸¸: {str(e)}"
            logger.error(f"âŒ {error_msg}")
            raise
    
    def parse_search_output(self, output: str, dataset: str) -> List[Dict[str, Any]]:
        """è§£ææœç´¢è¾“å‡ºç»“æœ"""
        results = []
        
        try:
            # è§£ææœç´¢ç»“æœçš„ç®€åŒ–ç‰ˆæœ¬
            # æŸ¥æ‰¾æ€§èƒ½æŒ‡æ ‡è¡Œ
            lines = output.split('\n')
            
            current_model = None
            for line in lines:
                line = line.strip()
                
                # æŸ¥æ‰¾æ¨¡å‹åç§°
                if 'ğŸ“Š' in line and dataset in line:
                    current_model = line.split('ğŸ“Š')[1].strip()
                
                # æŸ¥æ‰¾æ€§èƒ½æŒ‡æ ‡
                if current_model and any(metric in line for metric in ['recall@', 'search_time:', 'QPS:']):
                    if 'recall@1:' in line:
                        recall_1 = float(line.split(':')[1].strip())
                    elif 'recall@10:' in line:
                        recall_10 = float(line.split(':')[1].strip())
                    elif 'recall@100:' in line:
                        recall_100 = float(line.split(':')[1].strip())
                    elif 'search_time:' in line:
                        search_time = float(line.split(':')[1].strip().replace('s', ''))
                    elif 'QPS:' in line:
                        qps = float(line.split(':')[1].strip())
                        
                        # æ”¶é›†ä¸€ä¸ªæ¨¡å‹çš„å®Œæ•´ç»“æœ
                        if current_model:
                            model_result = {
                                "model_name": current_model,
                                "dataset": dataset,
                                "recall@1": locals().get('recall_1', 0.0),
                                "recall@10": locals().get('recall_10', 0.0),
                                "recall@100": locals().get('recall_100', 0.0),
                                "search_time": locals().get('search_time', 0.0),
                                "qps": qps
                            }
                            results.append(model_result)
                            current_model = None
            
            logger.info(f"âœ… æˆåŠŸè§£æ {len(results)} ä¸ªæ¨¡å‹çš„æœç´¢ç»“æœ")
            return results
            
        except Exception as e:
            logger.warning(f"âš ï¸ æœç´¢ç»“æœè§£æå¤±è´¥: {str(e)}")
            logger.warning("è¿”å›ç©ºç»“æœåˆ—è¡¨")
            return []
    
    def save_dataset_results(self, dataset: str, build_results: List[Dict], search_results: List[Dict]):
        """ä¿å­˜å•ä¸ªæ•°æ®é›†çš„ç»“æœ"""
        results_dir = f"results/{dataset}"
        
        # ä¿å­˜æ„å»ºç»“æœ
        build_csv_path = f"{results_dir}/build_results.csv"
        self.save_csv(build_results, build_csv_path)
        
        # ä¿å­˜æœç´¢ç»“æœ
        search_csv_path = f"{results_dir}/search_results.csv"
        self.save_csv(search_results, search_csv_path)
        
        # ç”Ÿæˆæ‘˜è¦
        summary_data = self.generate_dataset_summary(dataset, build_results, search_results)
        summary_csv_path = f"{results_dir}/summary.csv"
        self.save_csv([summary_data], summary_csv_path)
        
        logger.info(f"ğŸ’¾ {dataset}æ•°æ®é›†ç»“æœå·²ä¿å­˜åˆ° {results_dir}/")
    
    def save_csv(self, data: List[Dict], filepath: str):
        """ä¿å­˜CSVæ–‡ä»¶"""
        if not data:
            logger.warning(f"âš ï¸ æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡ä¿å­˜: {filepath}")
            return
        
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        
        with open(filepath, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=data[0].keys())
            writer.writeheader()
            writer.writerows(data)
        
        logger.info(f"ğŸ’¾ CSVæ–‡ä»¶å·²ä¿å­˜: {filepath}")
    
    def generate_dataset_summary(self, dataset: str, build_results: List[Dict], search_results: List[Dict]) -> Dict[str, Any]:
        """ç”Ÿæˆæ•°æ®é›†æ‘˜è¦"""
        return {
            "dataset": dataset,
            "total_models": len(build_results),
            "successful_builds": len([r for r in build_results if r["status"] == "Success"]),
            "total_build_time": sum(r["build_time"] for r in build_results),
            "dimension": build_results[0]["dimension"] if build_results else 0,
            "algorithms_used": list(set(r["algorithm"] for r in build_results)),
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        }
    
    def run_dataset_experiment(self, dataset: str):
        """è¿è¡Œå•ä¸ªæ•°æ®é›†çš„å®Œæ•´å®éªŒ"""
        logger.info(f"ğŸš€ å¼€å§‹{dataset}æ•°æ®é›†å®éªŒ")
        start_time = time.time()
        
        try:
            # ç”Ÿæˆå®éªŒé…ç½®
            configs = self.generate_experiment_configs(dataset)
            
            # æ„å»ºæ‰€æœ‰æ¨¡å‹
            build_results = []
            for i, config in enumerate(configs, 1):
                logger.info(f"ğŸ“Š è¿›åº¦: {i}/{len(configs)} - {dataset}")
                result = self.build_single_model(config)
                build_results.append(result)
            
            # è¿è¡Œæœç´¢æµ‹è¯•
            search_results = self.run_search_test(dataset)
            
            # ä¿å­˜ç»“æœ
            self.save_dataset_results(dataset, build_results, search_results)
            
            elapsed_time = time.time() - start_time
            logger.info(f"âœ… {dataset}æ•°æ®é›†å®éªŒå®Œæˆ! è€—æ—¶: {elapsed_time/60:.1f}åˆ†é’Ÿ")
            
            return build_results, search_results
            
        except Exception as e:
            logger.error(f"âŒ {dataset}æ•°æ®é›†å®éªŒå¤±è´¥: {str(e)}")
            logger.error("ğŸ›‘ æ ¹æ®é”™è¯¯å¤„ç†ç­–ç•¥ï¼Œåœæ­¢æ•´ä¸ªå®éªŒ")
            raise
    
    def run_complete_experiment(self):
        """è¿è¡Œå®Œæ•´å®éªŒ"""
        logger.info("ğŸ¯ å¼€å§‹å®Œæ•´çš„PQ vs RQæ€§èƒ½å¯¹æ¯”å®éªŒ")
        logger.info(f"ğŸ“‹ å®éªŒè§„æ¨¡: {len(self.datasets)}ä¸ªæ•°æ®é›† Ã— {len(self.k_values)}ä¸ªKå€¼ Ã— {len(self.target_bits)}ä¸ªç¼–ç é•¿åº¦ = {len(self.datasets) * len(self.k_values) * len(self.target_bits)}ä¸ªæ¨¡å‹")
        
        total_start_time = time.time()
        all_build_results = []
        all_search_results = []
        
        try:
            for dataset in self.datasets:
                build_results, search_results = self.run_dataset_experiment(dataset)
                all_build_results.extend(build_results)
                all_search_results.extend(search_results)
            
            # ä¿å­˜æœ€ç»ˆæ±‡æ€»ç»“æœ
            self.save_final_results(all_build_results, all_search_results)
            
            total_time = time.time() - total_start_time
            logger.info(f"ğŸ‰ å®Œæ•´å®éªŒæˆåŠŸå®Œæˆ! æ€»è€—æ—¶: {total_time/3600:.2f}å°æ—¶")
            
        except Exception as e:
            logger.error(f"âŒ å®éªŒå¤±è´¥: {str(e)}")
            logger.error("ğŸ›‘ å®éªŒå·²åœæ­¢")
            sys.exit(1)
    
    def save_final_results(self, all_build_results: List[Dict], all_search_results: List[Dict]):
        """ä¿å­˜æœ€ç»ˆæ±‡æ€»ç»“æœ"""
        # ä¿å­˜å®Œæ•´æ„å»ºç»“æœ
        self.save_csv(all_build_results, "final_results/all_build_results.csv")
        
        # ä¿å­˜å®Œæ•´æœç´¢ç»“æœ
        self.save_csv(all_search_results, "final_results/all_search_results.csv")
        
        # ç”Ÿæˆå®éªŒæ‘˜è¦
        summary = self.generate_experiment_summary(all_build_results, all_search_results)
        self.save_csv([summary], "final_results/experiment_summary.csv")
        
        logger.info("ğŸ’¾ æœ€ç»ˆç»“æœå·²ä¿å­˜åˆ° final_results/")
    
    def generate_experiment_summary(self, build_results: List[Dict], search_results: List[Dict]) -> Dict[str, Any]:
        """ç”Ÿæˆå®éªŒæ‘˜è¦"""
        return {
            "total_models": len(build_results),
            "successful_models": len([r for r in build_results if r["status"] == "Success"]),
            "total_build_time_hours": sum(r["build_time"] for r in build_results) / 3600,
            "datasets_tested": len(self.datasets),
            "algorithms_tested": list(set(r["algorithm"] for r in build_results)),
            "k_values_tested": self.k_values,
            "target_bits_tested": self.target_bits,
            "experiment_date": time.strftime("%Y-%m-%d"),
            "experiment_duration_hours": time.time() / 3600  # éœ€è¦å®é™…è®¡ç®—
        }

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨è‡ªåŠ¨åŒ–PQ vs RQæ€§èƒ½å¯¹æ¯”å®éªŒ")
    print("=" * 80)
    
    runner = ExperimentRunner()
    runner.run_complete_experiment()

if __name__ == "__main__":
    main() 